{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG16 fine tuning for colonoscopy polyps\n",
    "\n",
    "In the previous notebook ([4-TransferLearning.ipynb](4-TransferLearning.ipynb)) I tested the VGG16 transfer learning by training only the last FC layer. All the other convolutions blocks had the weights from the pre-trained VGG16.\n",
    "\n",
    "This notebook, I will try to apply a fine tuning: to train 1 or 2 convolutional blocks + FC layer. The FC layer will use initial weights from the best model obtained in the previous step (Transfer Learning notebook). See more details at [Keras blog](https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html).\n",
    "\n",
    "Let's load some libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python35\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import applications\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "from numpy.random import seed\n",
    "from tensorflow import set_random_seed\n",
    "import time, os\n",
    "import numpy as np\n",
    "import keras\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from __future__ import with_statement\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definition of paths for dataset, previous trained weights for the FC layer, earlystopping model, etc.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder to save the models\n",
    "modelFolder = 'saved_models'\n",
    "\n",
    "# Path to the file with the weights of the pre-trained VGG16 model\n",
    "weights_path = 'nets/vgg16_weights.h5'\n",
    "\n",
    "# Path to the previous saved top model weights (FC layer trained in Transfer Learning notebook)\n",
    "top_model_weights_path = os.path.join(modelFolder,'transferVGG16_bottleneck_fc_model.h5')\n",
    "\n",
    "# Earlystoping saved model - this name will be modified later by including parameter values\n",
    "earlystoping_path = './saved_models/fineTunning_earlystopnning.h5'\n",
    "\n",
    "# Dimensions of our images\n",
    "img_width, img_height = 150, 150\n",
    "\n",
    "# Train & validation images folders\n",
    "train_data_dir      = 'data_polyps/train'\n",
    "validation_data_dir = 'data_polyps/validation'\n",
    "\n",
    "# Train parameters\n",
    "nb_train_samples      = 910 # number of samples for training\n",
    "nb_validation_samples = 302 # number of samples for validation\n",
    "epochs = 300\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definition of the function that will do a fine tuning of the pre-trained VGG16 using FC layer weights trained in the previous notebook:\n",
    "* Load the pre-trained VGG16 as the lower model,\n",
    "* Add the top model as a FC layer,\n",
    "* Load the previous calculated weights for the FC layer,\n",
    "* Freeze a number of layers (a specific number of convolutional blocks): to freeze the last Conv block, freeze 15 layers; to freeze 2 last conv blocks, freeze only 11 layers.\n",
    "* Compilte the computational graph of the model,\n",
    "* Generate training & validation datasets from folders using data augmentation,\n",
    "* Use earlystopping if the validation accuracy is not increasing in 10 iterations,\n",
    "* Save the last best model,\n",
    "* Use SGD optimizer,\n",
    "* Search the best model using different values for the main hyperparameters: epochs, batch size, learning rate, momentum, and the number of layers to freeze.\n",
    "\n",
    "See more details at [Keras blog](https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html).\n",
    "\n",
    "In the first step, I will try one set of parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FineTunningVGG(epochs, batch_size, learning, mom, freezeLayers):\n",
    "    # Fine tuning function using VGG16 and our weights for the FC layer (top model)\n",
    "    \n",
    "    # Set seeeds for reproductibility\n",
    "    seed(1)            # numpy seed\n",
    "    set_random_seed(2) # tensorflow seed\n",
    "    \n",
    "    # Build the VGG16 block using our input size 150, 150, 3\n",
    "    base_model = applications.VGG16(weights='imagenet', include_top=False, input_shape=(150,150,3))\n",
    "\n",
    "    # Build a classifier model to put on top of the convolutional model (FC layer / top model)\n",
    "    top_model = Sequential()\n",
    "    top_model.add(Flatten(input_shape=base_model.output_shape[1:]))\n",
    "    top_model.add(Dense(256, activation='relu'))\n",
    "    top_model.add(Dropout(0.5))\n",
    "    top_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # Is necessary to start with a fully-trained classifier, including the top classifier,\n",
    "    # in order to successfully do fine-tuning\n",
    "    \n",
    "    # Load the previous calculated weight for the top model\n",
    "    top_model.load_weights(top_model_weights_path)\n",
    "\n",
    "    # Add the model on top of the convolutional base\n",
    "    model = Model(inputs= base_model.input, outputs= top_model(base_model.output))\n",
    "\n",
    "    # Set the first 'freezeLayers' layers to non-trainable (weights will not be updated)\n",
    "    # This number depends on the blocks to freeze: for the last Conv block freeze 15 layers,\n",
    "    # to freeze 2 last conv blocks freeze only 11 layers.\n",
    "    for layer in model.layers[:freezeLayers]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Compile the model with a SGD/momentum optimizer and a very slow learning rate.\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer= optimizers.SGD(lr=learning, momentum=mom), # lr=1e-4, momentum=0.9\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # Prepare data augmentation configuration\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rescale = 1. / 255,\n",
    "        shear_range = 0.2,\n",
    "        zoom_range = 0.2,\n",
    "        horizontal_flip = True,\n",
    "        vertical_flip = True,\n",
    "        rotation_range = 90)\n",
    "\n",
    "    test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "    # Generate training and validation data\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_height, img_width),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')\n",
    "\n",
    "    validation_generator = test_datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(img_height, img_width),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')\n",
    "\n",
    "    # Start timer\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Use earlystopping:\n",
    "    callbacks=[EarlyStopping(\n",
    "                            monitor='val_acc', \n",
    "                            patience=10,\n",
    "                            mode='max',\n",
    "                            verbose=1),\n",
    "                ModelCheckpoint(earlystoping_path[:-3]+'_e'+str(epochs)+'b'+str(batch_size)+'l'+str(learning)+'m'+str(mom)+'f'+str(freezeLayers)+'.h5',\n",
    "                            monitor='val_acc', \n",
    "                            save_best_only=True, \n",
    "                            mode='max',\n",
    "                            verbose=0)]\n",
    "\n",
    "    # Fine-tune the model\n",
    "    model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=nb_train_samples // batch_size,\n",
    "        epochs=epochs,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=nb_validation_samples // batch_size,\n",
    "        workers=7, # 7 cores of the CPU!\n",
    "        verbose = 0,\n",
    "        callbacks=callbacks) # remove this param if you dont need early stopping\n",
    "\n",
    "    # Print training time\n",
    "    print(\"Training time: %0.1f mins ---\" % ((time.time() - start_time)/60))\n",
    "\n",
    "    # Evaluate final test loss and accuracy scores\n",
    "    scoresVal = model.evaluate_generator(validation_generator, nb_validation_samples//batch_size, workers=7)\n",
    "    scoresTr  = model.evaluate_generator(train_generator, nb_train_samples//batch_size, workers=7)\n",
    "    # Print the results\n",
    "    print(freezeLayers, learning, mom, epochs, batch_size, scoresTr[0], scoresVal[0], scoresTr[1], scoresVal[1])\n",
    "\n",
    "    # clean some memory\n",
    "    del base_model\n",
    "    del top_model\n",
    "    del model\n",
    "\n",
    "    del train_datagen\n",
    "    del train_generator\n",
    "    del validation_generator\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Last Conv block + FC training\n",
    "\n",
    "Let's try the fine tuning for FC and only the last Conv block using `SGD` and earlystopping:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 910 images belonging to 2 classes.\n",
      "Found 302 images belonging to 2 classes.\n",
      "Epoch 00020: early stopping\n",
      "Training time: 0.8 mins ---\n",
      "15 0.0001 0.9 200 64 0.21136859910828726 0.18164563924074173 0.9084821428571429 0.9296875\n"
     ]
    }
   ],
   "source": [
    "FineTunningVGG(200, 64, 1e-4,  0.9, 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even after 200 epochs, the model is underfitter (validation ACC 92.9% vs training ACC 90.8%). We could decrease the drop rate but we are using the same top model for loading the weights.\n",
    "\n",
    "In the second step, let's try to use different paramters. You should use more values! With this function, you can search for several hyperparamters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freeze Learning Momentum epochs batch_size Loss_Tr Loos_Val Acc_Tr Acc_Val\n",
      "Found 910 images belonging to 2 classes.\n",
      "Found 302 images belonging to 2 classes.\n",
      "Epoch 00014: early stopping\n",
      "Training time: 0.7 mins ---\n",
      "15 1e-06 0.8 100 64 0.3496717576469694 0.267158854752779 0.8470982142857143 0.88671875\n",
      "Found 910 images belonging to 2 classes.\n",
      "Found 302 images belonging to 2 classes.\n",
      "Epoch 00014: early stopping\n",
      "Training time: 0.7 mins ---\n",
      "15 1e-06 0.9 100 64 0.3785088551895959 0.2557702325284481 0.8348214285714286 0.89453125\n",
      "Found 910 images belonging to 2 classes.\n",
      "Found 302 images belonging to 2 classes.\n",
      "Epoch 00014: early stopping\n",
      "Training time: 0.7 mins ---\n",
      "15 1e-05 0.8 100 64 0.3332709191100938 0.2718586437404156 0.8627232142857143 0.890625\n",
      "Found 910 images belonging to 2 classes.\n",
      "Found 302 images belonging to 2 classes.\n",
      "Epoch 00027: early stopping\n",
      "Training time: 1.2 mins ---\n",
      "15 1e-05 0.9 100 64 0.2671286410519055 0.24632438644766808 0.8895089285714286 0.90625\n",
      "Found 910 images belonging to 2 classes.\n",
      "Found 302 images belonging to 2 classes.\n",
      "Epoch 00019: early stopping\n",
      "Training time: 0.9 mins ---\n",
      "15 0.0001 0.8 100 64 0.24194059095212392 0.23600484430789948 0.8995535714285714 0.90625\n",
      "Found 910 images belonging to 2 classes.\n",
      "Found 302 images belonging to 2 classes.\n",
      "Epoch 00014: early stopping\n",
      "Training time: 0.7 mins ---\n",
      "15 0.0001 0.9 100 64 0.23978402146271297 0.2275155521929264 0.8939732142857143 0.90625\n",
      "Found 910 images belonging to 2 classes.\n",
      "Found 302 images belonging to 2 classes.\n",
      "Epoch 00030: early stopping\n",
      "Training time: 1.4 mins ---\n",
      "15 0.0005 0.8 100 64 0.1585572585463524 0.21986543387174606 0.9386160714285714 0.921875\n",
      "Found 910 images belonging to 2 classes.\n",
      "Found 302 images belonging to 2 classes.\n",
      "Epoch 00031: early stopping\n",
      "Training time: 1.4 mins ---\n",
      "15 0.0005 0.9 100 64 0.1188475601375103 0.18778885155916214 0.9620535714285714 0.94921875\n",
      "Found 910 images belonging to 2 classes.\n",
      "Found 302 images belonging to 2 classes.\n",
      "Epoch 00018: early stopping\n",
      "Training time: 0.9 mins ---\n",
      "15 0.001 0.8 100 64 0.28775997140577864 0.256353959441185 0.8939732142857143 0.91015625\n",
      "Found 910 images belonging to 2 classes.\n",
      "Found 302 images belonging to 2 classes.\n",
      "Epoch 00024: early stopping\n",
      "Training time: 1.1 mins ---\n",
      "15 0.001 0.9 100 64 0.33843035463775906 0.38016626983880997 0.8604910714285714 0.88671875\n",
      "Total time: 11.1 mins ---\n"
     ]
    }
   ],
   "source": [
    "# Start total timer\n",
    "start_time = time.time()\n",
    "\n",
    "# Change your hyperparamters to search for\n",
    "freezeLayersValues = [15] # 15 = freeze last Conv block, 11 = freeze last 2 Conv blocks\n",
    "learningValues = [1e-6, 1e-5, 1e-4, 5e-4, 1e-3]\n",
    "monValues = [0.8, 0.9]\n",
    "epochsValues = [100]\n",
    "batch_sizeValues = [64]\n",
    "\n",
    "# Print a header for results\n",
    "print('Freeze', 'Learning', 'Momentum', 'epochs', 'batch_size', 'Loss_Tr', 'Loos_Val', 'Acc_Tr', 'Acc_Val')\n",
    "for freezeLayers in freezeLayersValues: # \n",
    "    for learning in learningValues:\n",
    "        for mom in monValues:\n",
    "            for iepochs in epochsValues:\n",
    "                for ibatch_size in batch_sizeValues:\n",
    "                    try:\n",
    "                        # Try to execute the fine tuning function\n",
    "                        FineTunningVGG(iepochs, ibatch_size, learning, mom, freezeLayers)\n",
    "                    except:\n",
    "                        # If any error\n",
    "                        print('==> Error:', freezeLayers, learning, mom, iepochs, ibatch_size)\n",
    "\n",
    "# Print total execution time\n",
    "print(\"Total time: %0.1f mins ---\" % ((time.time() - start_time)/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With `learning rate=0.0005` and `momentum=0.9` it is possible to obtain `94.9%` validation accuracy (96.2% training accuracy). Let's try some close values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freeze Learning Momentum epochs batch_size Loss_Tr Loos_Val Acc_Tr Acc_Val\n",
      "Found 910 images belonging to 2 classes.\n",
      "Found 302 images belonging to 2 classes.\n",
      "Epoch 00022: early stopping\n",
      "Training time: 0.9 mins ---\n",
      "15 0.0002 0.9 100 64 0.1575070135295391 0.19659276492893696 0.9397321428571429 0.9375\n",
      "Found 910 images belonging to 2 classes.\n",
      "Found 302 images belonging to 2 classes.\n",
      "Epoch 00034: early stopping\n",
      "Training time: 1.3 mins ---\n",
      "15 0.0003 0.9 100 64 0.11700797293867383 0.14799168519675732 0.953125 0.94921875\n",
      "Found 910 images belonging to 2 classes.\n",
      "Found 302 images belonging to 2 classes.\n",
      "Epoch 00025: early stopping\n",
      "Training time: 1.0 mins ---\n",
      "15 0.0004 0.9 100 64 0.15608231403997966 0.18702777475118637 0.9397321428571429 0.94140625\n",
      "Found 910 images belonging to 2 classes.\n",
      "Found 302 images belonging to 2 classes.\n",
      "Epoch 00024: early stopping\n",
      "Training time: 0.9 mins ---\n",
      "15 0.0006 0.9 100 64 0.27273742854595184 0.33562444150447845 0.8895089285714286 0.8828125\n",
      "Found 910 images belonging to 2 classes.\n",
      "Found 302 images belonging to 2 classes.\n",
      "Epoch 00018: early stopping\n",
      "Training time: 0.7 mins ---\n",
      "15 0.0007 0.9 100 64 0.13509203387158258 0.2285628318786621 0.9497767857142857 0.9375\n",
      "Total time: 5.2 mins ---\n"
     ]
    }
   ],
   "source": [
    "# Start total timer\n",
    "start_time = time.time()\n",
    "\n",
    "# Change your hyperparamters to search for\n",
    "freezeLayersValues = [15] # 15 = freeze last Conv block, 11 = freeze last 2 Conv blocks\n",
    "learningValues = [2e-4, 3e-4, 4e-4, 6e-4, 7e-4]\n",
    "monValues = [0.9]\n",
    "epochsValues = [100]\n",
    "batch_sizeValues = [64]\n",
    "\n",
    "# Print a header for results\n",
    "print('Freeze', 'Learning', 'Momentum', 'epochs', 'batch_size', 'Loss_Tr', 'Loos_Val', 'Acc_Tr', 'Acc_Val')\n",
    "for freezeLayers in freezeLayersValues: # \n",
    "    for learning in learningValues:\n",
    "        for mom in monValues:\n",
    "            for iepochs in epochsValues:\n",
    "                for ibatch_size in batch_sizeValues:\n",
    "                    try:\n",
    "                        # Try to execute the fine tuning function\n",
    "                        FineTunningVGG(iepochs, ibatch_size, learning, mom, freezeLayers)\n",
    "                    except:\n",
    "                        # If any error\n",
    "                        print('==> Error:', freezeLayers, learning, mom, iepochs, ibatch_size)\n",
    "\n",
    "# Print total execution time\n",
    "print(\"Total time: %0.1f mins ---\" % ((time.time() - start_time)/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you remove the callbacks and use 200 epochs, you will be able to obtain even better accuracies:\n",
    "* 15 0.0005 0.8 200 64 0.03348573550049748 0.11928138509392738 0.9888392857142857 0.96875\n",
    "* 15 0.0005 0.9 200 64 0.022504917612033232 0.1295782057568431 0.9921875 0.96875\n",
    "* 15 0.0002 0.9 200 64 0.037957151753029654 0.11038850899785757 0.9888392857142857 0.98046875\n",
    "\n",
    "Thus, trainig 8 minutes the last Conv block and FC layer, you can obtain a `validation accuracy of 98%`!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Last 2 Conv block + FC training\n",
    "\n",
    "Let's see what ACC we could obtain if we train the last 2 Conv blocks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 910 images belonging to 2 classes.\n",
      "Found 302 images belonging to 2 classes.\n",
      "Epoch 00027: early stopping\n",
      "Training time: 1.3 mins ---\n",
      "11 0.0001 0.9 200 64 0.13032949502979005 0.18357415683567524 0.9553571428571429 0.9375\n"
     ]
    }
   ],
   "source": [
    "FineTunningVGG(200, 64, 1e-4,  0.9, 11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we expected, training more layers we are obtaining better results but the complexity of the model and the small dataset are starting to generate overfitting. Let's check different parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freeze Learning Momentum epochs batch_size Loss_Tr Loos_Val Acc_Tr Acc_Val\n",
      "Found 910 images belonging to 2 classes.\n",
      "Found 302 images belonging to 2 classes.\n",
      "Epoch 00018: early stopping\n",
      "Training time: 0.8 mins ---\n",
      "11 1e-06 0.8 100 64 0.35351393052509855 0.23303452879190445 0.8560267857142857 0.8984375\n",
      "Found 910 images belonging to 2 classes.\n",
      "Found 302 images belonging to 2 classes.\n",
      "Epoch 00018: early stopping\n",
      "Training time: 0.8 mins ---\n",
      "11 1e-06 0.9 100 64 0.3450494238308498 0.2228415459394455 0.8526785714285714 0.90625\n",
      "Found 910 images belonging to 2 classes.\n",
      "Found 302 images belonging to 2 classes.\n",
      "Epoch 00018: early stopping\n",
      "Training time: 0.8 mins ---\n",
      "11 1e-05 0.8 100 64 0.2748049093144281 0.21897215582430363 0.8861607142857143 0.91796875\n",
      "Found 910 images belonging to 2 classes.\n",
      "Found 302 images belonging to 2 classes.\n",
      "Epoch 00025: early stopping\n",
      "Training time: 1.1 mins ---\n",
      "11 1e-05 0.9 100 64 0.2397044769355229 0.20551345869898796 0.9040178571428571 0.93359375\n",
      "Found 910 images belonging to 2 classes.\n",
      "Found 302 images belonging to 2 classes.\n",
      "Epoch 00018: early stopping\n",
      "Training time: 0.8 mins ---\n",
      "11 0.0001 0.8 100 64 0.16343482796634948 0.1716460958123207 0.9352678571428571 0.9296875\n",
      "Found 910 images belonging to 2 classes.\n",
      "Found 302 images belonging to 2 classes.\n",
      "Epoch 00018: early stopping\n",
      "Training time: 0.8 mins ---\n",
      "11 0.0001 0.9 100 64 0.2808074599930218 0.30916735529899597 0.8560267857142857 0.86328125\n",
      "Found 910 images belonging to 2 classes.\n",
      "Found 302 images belonging to 2 classes.\n",
      "Epoch 00034: early stopping\n",
      "Training time: 1.5 mins ---\n",
      "11 0.0005 0.8 100 64 0.07953932375780173 0.13851428218185902 0.9698660714285714 0.94921875\n",
      "Found 910 images belonging to 2 classes.\n",
      "Found 302 images belonging to 2 classes.\n",
      "Epoch 00018: early stopping\n",
      "Training time: 0.8 mins ---\n",
      "11 0.0005 0.9 100 64 0.10966729692050389 0.17395678348839283 0.9508928571428571 0.93359375\n",
      "Total time: 8.1 mins ---\n"
     ]
    }
   ],
   "source": [
    "# Start total timer\n",
    "start_time = time.time()\n",
    "\n",
    "# Change your hyperparamters to search for\n",
    "freezeLayersValues = [11] # 15 = freeze last Conv block, 11 = freeze last 2 Conv blocks\n",
    "learningValues = [1e-6, 1e-5, 1e-4, 5e-4]\n",
    "monValues = [0.8, 0.9]\n",
    "epochsValues = [100]\n",
    "batch_sizeValues = [64]\n",
    "\n",
    "# Print a header for results\n",
    "print('Freeze', 'Learning', 'Momentum', 'epochs', 'batch_size', 'Loss_Tr', 'Loos_Val', 'Acc_Tr', 'Acc_Val')\n",
    "for freezeLayers in freezeLayersValues: # \n",
    "    for learning in learningValues:\n",
    "        for mom in monValues:\n",
    "            for iepochs in epochsValues:\n",
    "                for ibatch_size in batch_sizeValues:\n",
    "                    try:\n",
    "                        # Try to execute the fine tuning function\n",
    "                        FineTunningVGG(iepochs, ibatch_size, learning, mom, freezeLayers)\n",
    "                    except:\n",
    "                        # If any error\n",
    "                        print('==> Error:', freezeLayers, learning, mom, iepochs, ibatch_size)\n",
    "\n",
    "# Print total execution time\n",
    "print(\"Total time: %0.1f mins ---\" % ((time.time() - start_time)/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you remove the callbacks and use 200 epochs, you will be able to obtain even better accuracies over 96%.\n",
    "\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "* If you apply the fine tuning for the last conv block of VGG16 + FC (top model) you can obtain an accuracy `over 98%` (learning rate = 0.0002, momentum = 0.9, batch size = 64). This values is better compare with the small CNN results (`over 92%`).\n",
    "* The search space was limited and possible additional hyperparameter combinations should be tested including drop rate, optimizer or the base model (not only VGG16, it could be Inception, etc.).\n",
    "\n",
    "If you need a classifier to detect polyps in your colonoscopy images, you could try a small CNN with only few hiden layers. If you need accuracy over 98% you should try fine tuning.\n",
    "\n",
    "Let's find polyps into a colonoscopy image in the next script ([6-WindowsPolypsDetection.ipynb](6-WindowsPolypsDetection.ipynb)).\n",
    "\n",
    "Have fun with DL! @muntisa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acknowledgements\n",
    "\n",
    "I gratefully acknowledge the support of NVIDIA Corporation with the donation of the Titan Xp GPU used for this research ([https://developer.nvidia.com/academic_gpu_seeding](https://developer.nvidia.com/academic_gpu_seeding))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
